import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import argparse
from models import *
import matplotlib.pyplot as plt
import numpy as np
import argparse

# initialize weights to be guassians with mean=0 and stddev=0.02
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--lr', type=float, default=4e-3)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--epochs', type=int, default=3)
    # parser.add_argument('--d_steps', type=int, default=5)
    parser.add_argument('--momentum', type=float, default=0.9)
    parser.add_argument('--beta1', type=float, default=0.5)
    parser.add_argument('--beta2', type=float, default=0.99)
    parser.add_argument('--g_weights_path', type=str, default='./saved_weights/dcgan_gen.pth')
    parser.add_argument('--d_weights_path', type=str, default='./saved_weights/dcgan_dis.pth')
    parser.add_argument('--data_path', type=str, default='./dcgan/data')

    args = parser.parse_args()

    dataset = torchvision.datasets.ImageFolder(root=args.data_path,
                            transform=transforms.Compose([
                               transforms.Resize(64),
                               transforms.CenterCrop(64),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ])
    )

    dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,
                                         shuffle=True)

    USE_CUDA = torch.cuda.is_available()
    device = torch.device("cuda" if USE_CUDA else "cpu")

    G = Generator()
    D = Discriminator()
    G.to(device)
    D.to(device)

    G.apply(weights_init)
    D.apply(weights_init)

    real_label = 1.
    fake_label = 0.

    optim_g = optim.Adam(params=G.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))
    optim_d = optim.Adam(params=D.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))

    bce = nn.BCELoss()

    for it in range(1, args.epochs + 1):
       for i, data in enumerate(dataloader):
            # 1. Train discriminator: maximize log(D(x)) + log(1 - D(G(z)))
            # compute discriminator loss on real images
            optim_d.zero_grad()
            batch_size = data[0].size(0)
            inputs = data[0].to(device)
            real_labels = torch.full(size=(batch_size, ), fill_value=real_label, device=device)

            d_out_real = D(inputs).view(-1)
            real_loss = bce(d_out_real, real_labels)

            # compute discriminator loss on fake images generated by G
            fake_labels = torch.full(size=(batch_size, ), fill_value=fake_label, device=device)
            noise = torch.randn(size=(batch_size, 100, 1, 1), device=device)
            fake_images = G(noise)
            d_out_fake = D(fake_images).view(-1)
            fake_loss = bce(d_out_fake, fake_labels)

            # Gradient descent on D:
            d_loss = real_loss + fake_loss
            d_loss.backward()
            optim_d.step()
        
            # 2. Train generator: minimize -log(G(z))
            optim_g.zero_grad()
            noise = torch.randn(size=(batch_size, 100, 1, 1), device=device)
            real_labels = torch.full(size=(batch_size, ), fill_value=real_label, device=device)

            g_out = G(noise)
            g_loss = bce(D(g_out).view(-1), real_labels)
            g_loss.backward()
            optim_g.step()

            print(f'batch {i} complete')